{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA5709_Capstone_preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tzfnXylOB6-L",
        "y2Mcew6SdolD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ-1JerIttJ2"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13Fiai89Jo5lsOLRRYlkKMVongEHt6W-A?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn4jFm-43Nqr"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtjDeixFigEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0662300-1e3d-451c-81a7-21d2f5eedfc1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "\n",
        "\n",
        "input_month = \"06\" # this global variable is used to download/save file according to the month\n",
        "file_prefix = \"/content/gdrive/Shareddrives/Education/5709_Capstone/taxi_\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzfnXylOB6-L"
      },
      "source": [
        "## Cleaning function define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwepqDu9Ou4V"
      },
      "source": [
        "def request_write(input_str, input_month):\n",
        "    url = \"https://nyc-tlc.s3.amazonaws.com/trip+data/\"+input_str+\"_tripdata_2019-\"+input_month+\".csv\"\n",
        "    !wget $url\n",
        "\n",
        "# final_col_set = [\"PULocationID\", \"DOLocationID\", \"PU_datetime\", \"DO_datetime\", \"taxi\", \"weekNum\", \"hour_of_day\", \"min_cat\"]\n",
        "final_col_set = [\"PULocationID\", \"DOLocationID\", \"PU_datetime\", \"DO_datetime\", \"taxi\"]\n",
        "\n",
        "def time_series_process(input_pd, month):\n",
        "    # changes apply to the external variables, by reference\n",
        "    input_pd.PU_datetime = pd.to_datetime(input_pd.PU_datetime).dt.floor('10min') # floor to nearest 10 min\n",
        "    input_pd.drop(input_pd[(input_pd.PU_datetime.dt.year != 2019) | (input_pd.PU_datetime.dt.month != int(month))].index, inplace=True) # because some file contains more than this month\n",
        "    input_pd.DO_datetime = pd.to_datetime(input_pd.DO_datetime).dt.floor('10min')\n",
        "    input_pd.drop(input_pd[(input_pd.DO_datetime.dt.year != 2019) | (input_pd.DO_datetime.dt.month != int(month))].index, inplace=True)\n",
        "    # input_pd['weekNum'] = input_pd.PU_datetime.dt.day_name()\n",
        "    # input_pd['hour_of_day'] = input_pd.PU_datetime.dt.hour\n",
        "    # input_pd['min_cat'] = input_pd.PU_datetime.dt.minute\n",
        "    input_pd.drop(columns = [col for col in input_pd if col not in final_col_set], inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Mcew6SdolD"
      },
      "source": [
        "## Preprocess and save on each dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdwv7MRIal4U"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLo2gTtJaAHH"
      },
      "source": [
        "request_write(\"green\", input_month)\n",
        "request_write(\"yellow\", input_month)\n",
        "request_write(\"fhvhv\", input_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgWU0Nxcajq1"
      },
      "source": [
        "Green"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWYDmQcwaC39",
        "outputId": "a2337549-9585-4e97-f25d-79cfb6c70487"
      },
      "source": [
        "%%time\n",
        "taxi_green = pd.read_csv(\"/content/green_tripdata_2019-\"+input_month+\".csv\")\\\n",
        "                    .rename(columns={'lpep_pickup_datetime':'PU_datetime',\"lpep_dropoff_datetime\": \"DO_datetime\"})\n",
        "taxi_green[\"taxi\"] = \"green\"\n",
        "time_series_process(taxi_green, input_month)\n",
        "taxi_green = taxi_green[final_col_set] # order the columns\n",
        "taxi_green.to_csv(file_prefix + input_month + \"_all.csv\", index=False)\n",
        "# clean up memory\n",
        "del taxi_green"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.91 s, sys: 546 ms, total: 7.46 s\n",
            "Wall time: 31.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKbLyjqTaiV1"
      },
      "source": [
        "Yellow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhSTk7FVaO8O",
        "outputId": "3cd34c55-dbc7-425c-b057-b560f479f9c7"
      },
      "source": [
        "%%time\n",
        "taxi_yellow = pd.read_csv(\"/content/yellow_tripdata_2019-\"+input_month+\".csv\")\\\n",
        "            .rename(columns={'tpep_pickup_datetime':'PU_datetime',\"tpep_dropoff_datetime\": \"DO_datetime\"})\n",
        "taxi_yellow[\"taxi\"] = \"yellow\"\n",
        "time_series_process(taxi_yellow, input_month)\n",
        "taxi_yellow = taxi_yellow[final_col_set] # order the columns\n",
        "taxi_yellow.to_csv(file_prefix + input_month + \"_all.csv\", mode='a', header=False, index=False)\n",
        "# clean up memory\n",
        "del taxi_yellow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 54.1 s, sys: 6.04 s, total: 1min\n",
            "Wall time: 1min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOe6W2OKafbd"
      },
      "source": [
        "FHVHV (too large, needs to read in chunks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYSAxSysjMzV",
        "outputId": "667c0b19-07f8-4d43-f0be-0430e84f636f"
      },
      "source": [
        "%%time\n",
        "chunksize = 1e6\n",
        "chunk_list = []\n",
        "taxi_fhvhv_chunk = pd.read_csv(\"/content/fhvhv_tripdata_2019-\"+input_month+\".csv\", chunksize=chunksize)\n",
        "for chunk in taxi_fhvhv_chunk:\n",
        "    chunk.rename(columns={'pickup_datetime':'PU_datetime',\"dropoff_datetime\": \"DO_datetime\", \"hvfhs_license_num\": \"taxi\"}, inplace = True)\n",
        "    chunk[\"taxi\"] = chunk.taxi.map({\"HV0003\": \"uber\", \"HV0004\": \"via\", \"HV0005\": \"lyft\"}, na_action = \"ignore\")\n",
        "    time_series_process(chunk, input_month)\n",
        "    chunk_list.append(chunk)\n",
        "# clean up memory\n",
        "del taxi_fhvhv_chunk\n",
        "tmp = pd.concat(chunk_list)\n",
        "del chunk_list\n",
        "tmp = tmp[final_col_set] # order the columns\n",
        "tmp.to_csv(file_prefix + input_month + \"_all.csv\", mode='a', header=False, index=False)\n",
        "del tmp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 27s, sys: 6.04 s, total: 2min 33s\n",
            "Wall time: 2min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpX2jmz_dvIb"
      },
      "source": [
        "The resulting file is huge. \n",
        "\n",
        "Look like this:\n",
        "\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PULocationID</th>\n",
        "      <th>DOLocationID</th>\n",
        "      <th>PU_datetime</th>\n",
        "      <th>DO_datetime</th>\n",
        "      <th>taxi</th>\n",
        "      <th>weekNum</th>\n",
        "      <th>hour_of_day</th>\n",
        "      <th>min_cat</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>74</td>\n",
        "      <td>263</td>\n",
        "      <td>2019-06-01 00:20:00</td>\n",
        "      <td>2019-06-01 00:33:52</td>\n",
        "      <td>green</td>\n",
        "      <td>Saturday</td>\n",
        "      <td>0</td>\n",
        "      <td>20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>75</td>\n",
        "      <td>74</td>\n",
        "      <td>2019-06-01 00:30:00</td>\n",
        "      <td>2019-06-01 00:46:38</td>\n",
        "      <td>green</td>\n",
        "      <td>Saturday</td>\n",
        "      <td>0</td>\n",
        "      <td>30</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>75</td>\n",
        "      <td>74</td>\n",
        "      <td>2019-06-01 00:50:00</td>\n",
        "      <td>2019-06-01 01:00:29</td>\n",
        "      <td>green</td>\n",
        "      <td>Saturday</td>\n",
        "      <td>0</td>\n",
        "      <td>50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>255</td>\n",
        "      <td>37</td>\n",
        "      <td>2019-06-01 00:50:00</td>\n",
        "      <td>2019-06-01 01:10:07</td>\n",
        "      <td>green</td>\n",
        "      <td>Saturday</td>\n",
        "      <td>0</td>\n",
        "      <td>50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>41</td>\n",
        "      <td>116</td>\n",
        "      <td>2019-06-01 00:00:00</td>\n",
        "      <td>2019-06-01 00:15:45</td>\n",
        "      <td>green</td>\n",
        "      <td>Saturday</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "html = taxi_all.head().to_html()\n",
        "print(html)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwpKP3UYdi8Q"
      },
      "source": [
        "## Aggregation and save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nuQBIDPjFiE"
      },
      "source": [
        "[Pandas groupby](https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKI7gqThEuhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba7c5e8-7149-48a1-a87e-d7fe77b0f0d0"
      },
      "source": [
        "%%time\n",
        "\n",
        "def write_to_aggregate_file(req_datetime, req_LocationID, file_suffix):\n",
        "    # agg() returns only the count column with all group names as index, reset_index() split these group names into columns\n",
        "    taxi_agg_demand = taxi_all.groupby([req_datetime, req_LocationID, \"taxi\"]).agg(count = (\"taxi\", \"count\")).reset_index()\n",
        "    taxi_agg_demand.to_csv(file_prefix + file_suffix , index=False)\n",
        "\n",
        "for input_month in [\"07\", \"08\", \"09\"]:\n",
        "    taxi_all = pd.read_csv(file_prefix + input_month + \"_all.csv\")\n",
        "\n",
        "    # rewrite\n",
        "    time_series_process(taxi_all, input_month)\n",
        "    taxi_all = taxi_all[final_col_set] # order the columns\n",
        "    taxi_all.to_csv(file_prefix + input_month + \"_all.csv\", index=False)\n",
        "\n",
        "    req_datetime, req_LocationID, file_suffix = 'PU_datetime', 'PULocationID', input_month+\"_agg_demand.csv\"\n",
        "    write_to_aggregate_file(req_datetime, req_LocationID, file_suffix)\n",
        "\n",
        "    req_datetime, req_LocationID, file_suffix = 'DO_datetime', 'DOLocationID', input_month+\"_agg_supply.csv\"\n",
        "    write_to_aggregate_file(req_datetime, req_LocationID, file_suffix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11min 39s, sys: 31.7 s, total: 12min 11s\n",
            "Wall time: 13min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-WoSryPm4fs"
      },
      "source": [
        "The aggregated table looks like this:\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>DOLocationID</th>\n",
        "      <th>DO_datetime</th>\n",
        "      <th>taxi</th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 00:50:00</td>\n",
        "      <td>lyft</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 01:00:00</td>\n",
        "      <td>lyft</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 01:20:00</td>\n",
        "      <td>uber</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 01:40:00</td>\n",
        "      <td>lyft</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 01:40:00</td>\n",
        "      <td>uber</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PULocationID</th>\n",
        "      <th>PU_datetime</th>\n",
        "      <th>taxi</th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 00:00:00</td>\n",
        "      <td>via</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 00:20:00</td>\n",
        "      <td>via</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 01:00:00</td>\n",
        "      <td>via</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 01:10:00</td>\n",
        "      <td>via</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>1</td>\n",
        "      <td>2019-06-01 02:00:00</td>\n",
        "      <td>via</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ]
    }
  ]
}